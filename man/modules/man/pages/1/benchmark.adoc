include::../header.adoc[]

= BENCHMARK(1)

== NAME

benchmark - runs the BRL-CAD benchmark

== SYNOPSIS

_[OPTION=value] [cmd]*benchmark* [command] [OPTION=value] [RT_OPTIONS]_

== DESCRIPTION

The [cmd]*benchmark* suite will test the performance of a given system
by iteratively rendering several well-known datasets into 512x512
images where performance metrics are documented and fairly well
understood. The local machine performance is compared to the base
system (called VGR) and a numeric "VGR" multiplier of performance is
computed.  This number is a simplified metric from which one may
qualitatively compare cpu and cache performance, versions of BRL-CAD,
and different compiler characteristics.

Run without any arguments or variables set, the benchmark suite will
run a series of tests where it renders several image frames.  By
default, the benchmark suite will attempt to calibrate the intensity
of the test frames with the performance characteristics of the machine
running the tests.

There are several _OPTION_ environment variables that will modify how
the BRL-CAD benchmark behaves so that it may be run in a stand-alone
environment:

* _RT_ - the ray-trace binary (e.g. ../src/rt/rt or /usr/brlcad/bin/rt)
* _DB_ - the directory containing the reference geometry (e.g. ../db)
* _PIX_ - the directory containing the reference images (e.g. ../pix)
* _LOG_ - the directory containing the reference logs (e.g. ../pix)
* _CMP_ - the name of a pixel comparison tool (e.g. ./pixcmp or cmp)
* _ELP_ - the name of an elapsed time tool (e.g. ../sh/elapsed.sh)
* _TIMEFRAME_ - minimum number of seconds each ray-trace frame should take
* _MAXTIME_ - maximum number of seconds to spend on any test
* _DEVIATION_ - minimum sufficient % deviation from the average
* _AVERAGE_ - how many frames to average together
* _VERBOSE_ - turn on extra debug output (set to yes)
* _QUIET_ - turn off all output (set to yes)

The _TIMEFRAME_, _MAXTIME_, _DEVIATION_, and _AVERAGE_ options control
how the benchmark will proceed including how long it should take.
Each individual benchmark run will consume at least a minimum
_TIMEFRAME_ of wallclock time so that the results can stabilize.
After consuming at least the minimum _TIMEFRAME_, additional frames
may be computed until the standard deviation from the last _AVERAGE_
count of frames is below the specified _DEVIATION_.  When a test is
run and it completes in less than _TIMEFRAME_, the raytrace is
restarted using double the number of rays from the previous run.  If
the machine is fast enough, the benchmark may accelerate the number or
rays being fired.  These additional rays are hypersampled but without
any jitter, so it is effectively performing a multiplier amount of
work over the initial frame.

There are various __command__s that may be give to the BRL-CAD
benchmark that cause it to perform various actions such as invoking
the computation tests or filesystem clean-up:

* _clean_ - remove the test-specific pix and log files
* _clobber_ - same as clean, also benchmark.log files and user is prompted
* _help_ - displays a brief usage statement
* _instructions_ - displays more detailed usage instructions
* _quiet_ - quell printing output (still logs)
* _verbose_ - remove the test-specific pix and log files
* _clean_ - remove the test-specific pix and log files
* _run_ - initiate the benchmark analysis

When the benchmark completes, output should be saved to several log
files including a 'summary' file containing tabulated results, a
'benchmark.log' file containing the output from a given run, and
multiple log files for each test frame. Use the _clean_ and _clobber_
commands during execution to remove the files generated during the
benchmark.

The _clean_ command removes the test pix and log files.  The _clobber_
command removes those same files as well as any *benchmark.log files
encountered, and prompting the user beforehand. The generated tabular
_summary_ file will not be removed automatically regardless of
invocation command.  The _summary_ file must always be manually
deleted.

== REPORTING RESULTS

Please send your BRL-CAD Benchmark results to the developers along
with detailed system information to mailto:devs@brlcad.org[] Include
at least:

. Compiler name and version (e.g. `gcc --version`)

. CPU configuration (e.g. `cat /proc/cpuinfo` or `hinv` or `sysctl -a`)

. Cache (data and/or instruction) details for L1/L2/L3 and system
(e.g. `cat /proc/cpuinfo` or `hinv` or `sysctl -a`)

. All generated log files (i.e. *.log* after benchmark completes)

. Anything else you think might be relevant to performance

== EXAMPLES

* _benchmark run_ - default run of the suite, taking approximately 10
minutes

* _benchmark run TIMEFRAME=1_ - quick test run for testing functionality
and performance ballpark

* _benchmark run DEVIATION=1 TIMEFRAME=60 MAXTIME=600_ - excessive
analysis, attempt to stabilize within 1 percent deviation with each
frame taking at least 60 seconds but no more than 10 minutes per test
(the entire analysis will probably take 30 to 60 minutes)

* _benchmark run QUIET=1 -P1_ - perform a benchmark analysis only using
one CPU and only logging results to a file

* _benchmark clean_ - delete all of the log and pix image files
generated during a benchmark analysis, leaving only the summary file
and any *benchmark.log files

== SEE ALSO

xref:man:1/brlcad.adoc[*brlcad*(1)], xref:man:1/rt.adoc[*rt*(1)],
xref:man:1/pix-fb.adoc[*pix-fb*(1)],
xref:man:3/librt.adoc[*librt*(3)], xref:man:5/pix.adoc[*pix*(5)]

== AUTHOR

_BRL-CAD Team_

include::../footer.adoc[]
